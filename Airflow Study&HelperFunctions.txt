Airflow Study Case

(1)
bucket: telegraf
_measurement: cpu
_field: usage_user
cpu: cpu0
aggregate function : last

(2)
bucket: telegraf
_measurement: cpu
_field: usage_user
cpu: cpu1
aggregate function : last



(3)
bucket: telegraf
_measurement: disk
_field: free and total
device: sda1
aggregate function : last


(4)
bucket: telegraf
_measurement: mem
_field: used and total
aggregate function : last



Bu çalışmada Influxdb 2.1.1 sürümündeki sistem metrikleri üzerinden hesaplamalar Airflow kullanılarak yapılacaktır. 
Buradaki senaryoda sistem metriklerinin bir dashboard üzerinden görselleştirilmeye ihtiyacı vardır. 
Hedef dashboard hazırlayacak kişiye bu verilerin sorunsuz bir şekilde belirli aralıklarla sağlanmasıdır. (scheduler interval= 10 min)

Airflow kurulumu yapıldıktan sonra yapılacak işlem sırası şu şekilde olmalıdır:

- 1 nolu task sistemin kullandığı cpu0 değerini yüzdelik dilime çevirsin ve cloud üzerinde bigquery de bir table içerisine yazsın.
- 2 nolu task 1 nolu task çalıştıktan sonra aynı şekilde sistemin kullandığı cpu1 değerini yüzdelik dilim olarak hesaplayıp bigquerye yazsın.
- 3 ve 4 nolu tasklar 2 nolu task çalıştıktan sonra aynı anda çalışmaya başlasın ve her iki taskta toplam kaynak miktarının
   kullanılan kaynak miktarına oranını yüzdelik bir dilim olarak hesaplayıp bigqueryde table içerine yazsın.
- Bu tasklar bittikten sonra kendinizin hazırladığı bir shell script taskı çalışsın ve çıktı olarak tüm taskların başarılı bir şekilde bittiğini yazsın.
  
Not: Servisleri docker compose şeklinde ve LocalExecutor olarak kurabilirsiniz. Docker hub üzerinden Bitnami/airflow olarak aratabilirsiniz.



*****Helper Informations*******

Different secret key error for seeing log:

7J8b9XEwkQwO6f5UFgsXOQ==  scheduler secret key

iMU9jzpAPuAxOvb5tN9yhQ== uı secret key

hfh8yaXvuMg== worker secret key

You should set secret keys as same for each container(scheduler, worker, web UI)


Install any module:


sudo pip3 install virtualenv
virtualenv -p python3 (target folder)

pip3 install apache-airflow-providers-influxdb
$ sudo su -
# .  /opt/bitnami/airflow/venv/bin/activate
(venv) # pip3 install influxdb
...
(venv) # pip3 install influxdb-client

python3 -m venv --upgrade


Create User for UI:

airflow users create  --username admin --firstname Peter --lastname Parker --role Admin --password admin --email admin@airflow





Email Alert:

from airflow.operators.email_operator import EmailOperator


default_args = {
	'owner': ISTDSA
	'email': ['admin@airflow.com, airflow@airflow.com],
	'email_on_failure': True,
    'retries': 1
}






